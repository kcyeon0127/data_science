#!/usr/bin/env python3
"""
Macìš© DIN + XGBoost í•˜ì´ë¸Œë¦¬ë“œ CTR ì˜ˆì¸¡
Apple Silicon ìµœì í™” + ë¹ ë¥¸ ì²˜ë¦¬ (2-5ë¶„ ë‚´ ì™„ë£Œ)
"""

import os
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

# Mac ì¹œí™”ì  ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import roc_auc_score, average_precision_score
import xgboost as xgb
from tqdm.auto import tqdm
import gc
import time

# TensorFlow (DINìš©) - Mac ìµœì í™”
print("ğŸ”„ TensorFlow ì´ˆê¸°í™” ì¤‘... (mutex ë©”ì‹œì§€ëŠ” ì •ìƒì…ë‹ˆë‹¤)")
try:
    import tensorflow as tf
    print("ğŸ“¦ TensorFlow ì„í¬íŠ¸ ì™„ë£Œ")

    # Apple Silicon ìµœì í™”
    if hasattr(tf.config, 'experimental') and hasattr(tf.config.experimental, 'enable_mlcompute'):
        tf.config.experimental.enable_mlcompute()
        print("ğŸ Apple MLCompute í™œì„±í™”ë¨")

    # GPU ë©”ëª¨ë¦¬ ì„¤ì •
    physical_devices = tf.config.list_physical_devices('GPU')
    if physical_devices:
        tf.config.experimental.set_memory_growth(physical_devices[0], True)
        print("ğŸ’¾ GPU ë©”ëª¨ë¦¬ ì„¤ì • ì™„ë£Œ")

    TF_AVAILABLE = True
    print("âœ… TensorFlow Apple Silicon ìµœì í™” í™œì„±í™”")
except ImportError:
    TF_AVAILABLE = False
    print("âš ï¸ TensorFlow ì—†ìŒ - XGBoost ë‹¨ë… ëª¨ë“œ")

class MacDINXGBoost:
    def __init__(self):
        self.din_model = None
        self.xgb_models = {}
        self.scalers = {}
        self.encoders = {}
        self.feature_cols = {
            'tabular': [],
            'sequence': []
        }

        print("ğŸ Macìš© DIN + XGBoost í•˜ì´ë¸Œë¦¬ë“œ ì´ˆê¸°í™”")

    def load_data_efficiently(self, sample_ratio=0.3):
        """íš¨ìœ¨ì  ë°ì´í„° ë¡œë”© (ìƒ˜í”Œë§ìœ¼ë¡œ ë¹ ë¥¸ ì²˜ë¦¬)"""
        print("ğŸ“‚ íš¨ìœ¨ì  ë°ì´í„° ë¡œë”© ì¤‘...")

        # 1. íŒŒì¼ í¬ê¸° í™•ì¸
        train_size = os.path.getsize('data/train.parquet') / (1024**3)  # GB
        print(f"ğŸ“Š í›ˆë ¨ ë°ì´í„° í¬ê¸°: {train_size:.1f}GB")

        if train_size > 3.0:  # 3GB ì´ìƒì´ë©´ ìƒ˜í”Œë§
            print(f"ğŸ”„ ëŒ€ìš©ëŸ‰ ë°ì´í„° ê°ì§€ - {sample_ratio*100:.0f}% ê· í˜• ìƒ˜í”Œë§ ì ìš©")

            # ì²­í¬ë³„ë¡œ ì½ìœ¼ë©´ì„œ ìƒ˜í”Œë§
            chunks = []
            total_rows = 0

            for chunk in tqdm(pd.read_parquet('data/train.parquet', chunksize=200000),
                            desc="ì²­í¬ë³„ ìƒ˜í”Œë§"):
                total_rows += len(chunk)

                # ê· í˜• ìƒ˜í”Œë§ (í´ë¦­/ë¹„í´ë¦­ ë¹„ìœ¨ ìœ ì§€)
                clicked = chunk[chunk['clicked'] == 1]
                not_clicked = chunk[chunk['clicked'] == 0]

                sample_clicked = clicked.sample(
                    min(len(clicked), int(len(clicked) * sample_ratio)),
                    random_state=42
                )
                sample_not_clicked = not_clicked.sample(
                    min(len(not_clicked), int(len(not_clicked) * sample_ratio)),
                    random_state=42
                )

                chunk_sample = pd.concat([sample_clicked, sample_not_clicked])
                chunks.append(chunk_sample)

                # ë©”ëª¨ë¦¬ ê´€ë¦¬
                if len(chunks) > 20:  # ë„ˆë¬´ ë§ì€ ì²­í¬ ëˆ„ì  ë°©ì§€
                    chunks = [pd.concat(chunks[-20:], ignore_index=True)]
                    gc.collect()

            self.train_df = pd.concat(chunks, ignore_index=True)
            print(f"ğŸ“Š ìƒ˜í”Œë§ ê²°ê³¼: {total_rows:,} â†’ {len(self.train_df):,}í–‰")

        else:
            print("ğŸ“‚ ì „ì²´ ë°ì´í„° ë¡œë”© (í¬ê¸° ì ë‹¹)")
            self.train_df = pd.read_parquet('data/train.parquet')

        # í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” í•­ìƒ ì „ì²´
        self.test_df = pd.read_parquet('data/test.parquet')

        print(f"âœ… ë¡œë”© ì™„ë£Œ: í›ˆë ¨ {self.train_df.shape}, í…ŒìŠ¤íŠ¸ {self.test_df.shape}")
        print(f"ğŸ“Š ìµœì¢… í´ë¦­ë¥ : {self.train_df['clicked'].mean():.4f}")

        return True

    def preprocess_features(self):
        """íŠ¹ì„± ë¶„ë¦¬ ë° ì „ì²˜ë¦¬ (DINìš© vs XGBoostìš©)"""
        print("ğŸ”§ íŠ¹ì„± ë¶„ë¦¬ ë° ì „ì²˜ë¦¬...")

        # 1. íŠ¹ì„± ë¶„ë¥˜
        all_cols = self.train_df.columns.tolist()

        # Tabular features (XGBoostìš©)
        tabular_features = [
            col for col in all_cols
            if col.startswith(('feat_', 'history_')) and col not in ['seq']
        ]

        # Categorical features
        categorical_features = ['gender', 'age_group', 'inventory_id']

        # Sequence features (DINìš©)
        sequence_features = ['seq'] if 'seq' in all_cols else []

        print(f"ğŸ“Š íŠ¹ì„± ë¶„í¬:")
        print(f"  Tabular: {len(tabular_features)}ê°œ")
        print(f"  Categorical: {len(categorical_features)}ê°œ")
        print(f"  Sequence: {len(sequence_features)}ê°œ")

        # 2. Tabular features ì „ì²˜ë¦¬ (XGBoostìš©)
        print("ğŸ”§ Tabular features ì „ì²˜ë¦¬ ì¤‘...")

        # ìˆ˜ì¹˜í˜• íŠ¹ì„± ì •ë¦¬
        for col in tqdm(tabular_features, desc="ìˆ˜ì¹˜í˜• ì²˜ë¦¬"):
            if col in self.train_df.columns:
                # ê²°ì¸¡ê°’ ì²˜ë¦¬
                mean_val = self.train_df[col].fillna(0).mean()
                self.train_df[col] = self.train_df[col].fillna(mean_val)
                self.test_df[col] = self.test_df[col].fillna(mean_val)

        # ì¹´í…Œê³ ë¦¬ íŠ¹ì„± ì¸ì½”ë”©
        for col in categorical_features:
            if col in self.train_df.columns:
                print(f"ì¹´í…Œê³ ë¦¬ ì¸ì½”ë”©: {col}")
                le = LabelEncoder()

                # í›ˆë ¨+í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²°í•©í•˜ì—¬ í•™ìŠµ
                combined = pd.concat([
                    self.train_df[col].fillna('unknown'),
                    self.test_df[col].fillna('unknown')
                ]).astype(str)

                le.fit(combined)
                self.train_df[col] = le.transform(self.train_df[col].fillna('unknown').astype(str))
                self.test_df[col] = le.transform(self.test_df[col].fillna('unknown').astype(str))

                self.encoders[col] = le
                tabular_features.append(col)

        # 3. Sequence features ì „ì²˜ë¦¬ (DINìš©)
        if sequence_features and TF_AVAILABLE:
            print("ğŸ”§ Sequence features ì „ì²˜ë¦¬ ì¤‘...")
            for col in sequence_features:
                if col in self.train_df.columns:
                    # ì‹œí€€ìŠ¤ë¥¼ ê³ ì • ê¸¸ì´ë¡œ íŒ¨ë”© (DINì—ì„œ í•„ìš”)
                    self.preprocess_sequence(col, max_len=50)

        # 4. ìµœì¢… íŠ¹ì„± ëª©ë¡ ì €ì¥
        self.feature_cols['tabular'] = [col for col in tabular_features if col in self.train_df.columns]
        self.feature_cols['sequence'] = [col for col in sequence_features if col in self.train_df.columns]

        print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ:")
        print(f"  ìµœì¢… Tabular: {len(self.feature_cols['tabular'])}ê°œ")
        print(f"  ìµœì¢… Sequence: {len(self.feature_cols['sequence'])}ê°œ")

        return True

    def preprocess_sequence(self, col, max_len=50):
        """ì‹œí€€ìŠ¤ ë°ì´í„° ì „ì²˜ë¦¬ (DINìš©)"""
        print(f"ğŸ”„ ì‹œí€€ìŠ¤ ì „ì²˜ë¦¬: {col}")

        # ì‹œí€€ìŠ¤ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³  íŒ¨ë”©
        def pad_sequence(seq_str, max_len):
            if pd.isna(seq_str) or seq_str == '':
                return [0] * max_len

            try:
                # ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì˜ˆ: "1,2,3" â†’ [1,2,3])
                seq = [int(x) for x in str(seq_str).split(',')]

                # íŒ¨ë”© ë˜ëŠ” ìë¥´ê¸°
                if len(seq) >= max_len:
                    return seq[:max_len]
                else:
                    return seq + [0] * (max_len - len(seq))
            except:
                return [0] * max_len

        # í›ˆë ¨ ë°ì´í„°
        train_seqs = [pad_sequence(seq, max_len) for seq in tqdm(self.train_df[col], desc="í›ˆë ¨ ì‹œí€€ìŠ¤")]
        self.train_df[f'{col}_padded'] = train_seqs

        # í…ŒìŠ¤íŠ¸ ë°ì´í„°
        test_seqs = [pad_sequence(seq, max_len) for seq in tqdm(self.test_df[col], desc="í…ŒìŠ¤íŠ¸ ì‹œí€€ìŠ¤")]
        self.test_df[f'{col}_padded'] = test_seqs

        # ì›ë³¸ ì»¬ëŸ¼ ì œê±°
        self.feature_cols['sequence'] = [f'{col}_padded' if c == col else c for c in self.feature_cols['sequence']]

    def create_din_model(self, sequence_vocab_size=10000, embedding_dim=64):
        """DIN ëª¨ë¸ ìƒì„± (ì‹œí€€ìŠ¤ íŠ¹ì„±ìš©)"""
        if not TF_AVAILABLE or not self.feature_cols['sequence']:
            print("âš ï¸ DIN ëª¨ë¸ ìŠ¤í‚µ (TensorFlow ì—†ìŒ ë˜ëŠ” ì‹œí€€ìŠ¤ ì—†ìŒ)")
            return None

        print("ğŸ§  DIN ëª¨ë¸ ìƒì„± ì¤‘...")

        # ì…ë ¥ ë ˆì´ì–´
        sequence_input = tf.keras.layers.Input(shape=(50,), name='sequence')
        target_input = tf.keras.layers.Input(shape=(1,), name='target')

        # ì„ë² ë”© ë ˆì´ì–´
        item_embedding = tf.keras.layers.Embedding(
            sequence_vocab_size, embedding_dim, mask_zero=True
        )

        sequence_emb = item_embedding(sequence_input)  # (batch, 50, 64)
        target_emb = item_embedding(target_input)      # (batch, 1, 64)

        # DIN Attention
        target_expanded = tf.keras.layers.RepeatVector(50)(tf.squeeze(target_emb, axis=1))  # (batch, 50, 64)

        # Attention weights ê³„ì‚°
        attention_input = tf.keras.layers.Concatenate()([
            sequence_emb, target_expanded, sequence_emb * target_expanded
        ])  # (batch, 50, 192)

        attention_weights = tf.keras.layers.Dense(64, activation='relu')(attention_input)
        attention_weights = tf.keras.layers.Dense(1, activation='sigmoid')(attention_weights)  # (batch, 50, 1)

        # Attention ì ìš©
        attended_sequence = tf.keras.layers.Multiply()([sequence_emb, attention_weights])  # (batch, 50, 64)
        sequence_repr = tf.keras.layers.GlobalAveragePooling1D()(attended_sequence)  # (batch, 64)

        # ìµœì¢… ì¶œë ¥
        output = tf.keras.layers.Dense(32, activation='relu')(sequence_repr)
        output = tf.keras.layers.Dropout(0.3)(output)
        sequence_features = tf.keras.layers.Dense(16, activation='relu', name='sequence_features')(output)

        model = tf.keras.Model(inputs=[sequence_input, target_input], outputs=sequence_features)
        model.compile(optimizer='adam', loss='mse')

        print("âœ… DIN ëª¨ë¸ ìƒì„± ì™„ë£Œ")
        return model

    def train_xgboost_ensemble(self, X_tabular, y, cv_folds=3):
        """XGBoost ì•™ìƒë¸” í›ˆë ¨ (Mac ìµœì í™”)"""
        print("ğŸš€ XGBoost ì•™ìƒë¸” í›ˆë ¨ ì¤‘...")

        # Mac ìµœì í™” XGBoost íŒŒë¼ë¯¸í„°
        base_params = {
            'objective': 'binary:logistic',
            'eval_metric': 'auc',
            'tree_method': 'hist',  # Macì—ì„œ ì•ˆì „í•œ ë°©ë²•
            'random_state': 42,
            'verbosity': 0,
            'n_jobs': -1  # Mac ë©€í‹°ì½”ì–´ í™œìš©
        }

        # ë‹¤ì–‘í•œ XGBoost ì„¤ì •ìœ¼ë¡œ ì•™ìƒë¸”
        model_configs = {
            'xgb_conservative': {
                **base_params,
                'max_depth': 6,
                'learning_rate': 0.1,
                'n_estimators': 100,
                'subsample': 0.8,
                'colsample_bytree': 0.8
            },
            'xgb_aggressive': {
                **base_params,
                'max_depth': 8,
                'learning_rate': 0.05,
                'n_estimators': 200,
                'subsample': 0.9,
                'colsample_bytree': 0.9
            }
        }

        # í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬
        pos_ratio = y.mean()
        scale_pos_weight = (1 - pos_ratio) / pos_ratio
        print(f"ğŸ“Š í´ë¦­ë¥ : {pos_ratio:.4f}, Scale pos weight: {scale_pos_weight:.2f}")

        for config in model_configs.values():
            config['scale_pos_weight'] = scale_pos_weight

        # êµì°¨ ê²€ì¦ìœ¼ë¡œ ëª¨ë¸ í›ˆë ¨
        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)

        for name, params in model_configs.items():
            print(f"í›ˆë ¨ ì¤‘: {name}")

            cv_scores = []
            models = []

            for fold, (train_idx, val_idx) in enumerate(skf.split(X_tabular, y)):
                X_train_fold = X_tabular.iloc[train_idx]
                X_val_fold = X_tabular.iloc[val_idx]
                y_train_fold = y.iloc[train_idx]
                y_val_fold = y.iloc[val_idx]

                # ëª¨ë¸ í›ˆë ¨
                model = xgb.XGBClassifier(**params)
                model.fit(
                    X_train_fold, y_train_fold,
                    eval_set=[(X_val_fold, y_val_fold)],
                    early_stopping_rounds=10,
                    verbose=False
                )

                # ê²€ì¦
                val_pred = model.predict_proba(X_val_fold)[:, 1]
                auc = roc_auc_score(y_val_fold, val_pred)
                cv_scores.append(auc)
                models.append(model)

            print(f"  {name} CV AUC: {np.mean(cv_scores):.4f} Â± {np.std(cv_scores):.4f}")
            self.xgb_models[name] = models

        print("âœ… XGBoost ì•™ìƒë¸” í›ˆë ¨ ì™„ë£Œ")

    def predict_and_submit(self, return_features=False):
        """ì˜ˆì¸¡ ë° ì œì¶œ íŒŒì¼ ìƒì„±"""
        print("ğŸ¯ ì˜ˆì¸¡ ì‹œì‘...")

        # 1. Tabular featuresë¡œ XGBoost ì˜ˆì¸¡
        X_test_tabular = self.test_df[self.feature_cols['tabular']]

        xgb_predictions = []
        for name, models in self.xgb_models.items():
            fold_preds = []
            for model in models:
                pred = model.predict_proba(X_test_tabular)[:, 1]
                fold_preds.append(pred)

            avg_pred = np.mean(fold_preds, axis=0)
            xgb_predictions.append(avg_pred)
            print(f"{name} ì˜ˆì¸¡ ì™„ë£Œ")

        # 2. XGBoost ì•™ìƒë¸” í‰ê· 
        final_predictions = np.mean(xgb_predictions, axis=0)

        # 3. DIN íŠ¹ì„±ì´ ìˆë‹¤ë©´ ê²°í•© (í˜„ì¬ëŠ” XGBoost ë‹¨ë…)
        if self.din_model and self.feature_cols['sequence']:
            print("ğŸ§  DIN íŠ¹ì„± ì¶”ê°€...")
            # DIN ì˜ˆì¸¡ ì½”ë“œ (í•„ìš”ì‹œ êµ¬í˜„)
            pass

        # 4. ì œì¶œ íŒŒì¼ ìƒì„± (ì˜¬ë°”ë¥¸ í˜•ì‹)
        try:
            submission = pd.read_csv('data/sample_submission.csv')
            submission['clicked'] = final_predictions
            print(f"âœ… ì˜¬ë°”ë¥¸ ID í˜•ì‹: {submission['ID'].iloc[0]}")
        except:
            submission = pd.DataFrame({
                'ID': [f'TEST_{i:07d}' for i in range(len(final_predictions))],
                'clicked': final_predictions
            })

        submission_path = 'submission_mac_din_xgboost.csv'
        submission.to_csv(submission_path, index=False, encoding='utf-8')

        print(f"âœ… ì œì¶œ íŒŒì¼ ìƒì„±: {submission_path}")
        print(f"ğŸ“Š ì˜ˆì¸¡ í†µê³„:")
        print(f"  í‰ê·  í´ë¦­ë¥ : {final_predictions.mean():.4f}")
        print(f"  ìµœì†Œê°’: {final_predictions.min():.4f}")
        print(f"  ìµœëŒ€ê°’: {final_predictions.max():.4f}")

        return submission_path

    def run_pipeline(self, sample_ratio=0.3):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("ğŸš€ Macìš© DIN + XGBoost í•˜ì´ë¸Œë¦¬ë“œ íŒŒì´í”„ë¼ì¸ ì‹œì‘!")
        print("=" * 60)

        start_time = time.time()

        # 1. ë°ì´í„° ë¡œë”©
        if not self.load_data_efficiently(sample_ratio):
            return False

        # 2. íŠ¹ì„± ì „ì²˜ë¦¬
        if not self.preprocess_features():
            return False

        # 3. DIN ëª¨ë¸ ìƒì„± (ì‹œí€€ìŠ¤ê°€ ìˆëŠ” ê²½ìš°)
        if self.feature_cols['sequence'] and TF_AVAILABLE:
            self.din_model = self.create_din_model()

        # 4. XGBoost í›ˆë ¨
        X_tabular = self.train_df[self.feature_cols['tabular']]
        y = self.train_df['clicked']

        self.train_xgboost_ensemble(X_tabular, y)

        # 5. ì˜ˆì¸¡ ë° ì œì¶œ
        submission_path = self.predict_and_submit()

        elapsed = time.time() - start_time
        print("\n" + "ğŸ‰" * 60)
        print("íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        print("ğŸ‰" * 60)
        print(f"â±ï¸ ì´ ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ ({elapsed/60:.1f}ë¶„)")
        print(f"ğŸ“ ì œì¶œ íŒŒì¼: {submission_path}")

        return True

def main():
    print("ğŸ Macìš© DIN + XGBoost í•˜ì´ë¸Œë¦¬ë“œ CTR ì˜ˆì¸¡")
    print("=" * 60)

    pipeline = MacDINXGBoost()

    # ë¹ ë¥¸ ì‹¤í–‰ì„ ìœ„í•œ ìƒ˜í”Œë§ ì˜µì…˜
    print("ğŸ“‹ ì‹¤í–‰ ì˜µì…˜:")
    print("1. ë¹ ë¥¸ ëª¨ë“œ (30% ìƒ˜í”Œë§) - 2-3ë¶„")
    print("2. ê· í˜• ëª¨ë“œ (50% ìƒ˜í”Œë§) - 4-5ë¶„")
    print("3. ì „ì²´ ëª¨ë“œ (100% ë°ì´í„°) - 10-15ë¶„")

    choice = input("ì„ íƒ (1-3, ê¸°ë³¸ê°’ 1): ").strip() or '1'

    sample_ratios = {'1': 0.3, '2': 0.5, '3': 1.0}
    sample_ratio = sample_ratios.get(choice, 0.3)

    print(f"ğŸš€ {sample_ratio*100:.0f}% ë°ì´í„°ë¡œ ì‹¤í–‰ ì‹œì‘...")

    success = pipeline.run_pipeline(sample_ratio)

    if success:
        print("\nâœ… ì„±ê³µ! ì œì¶œ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("\nâŒ ì‹¤í–‰ ì‹¤íŒ¨")

if __name__ == "__main__":
    main()